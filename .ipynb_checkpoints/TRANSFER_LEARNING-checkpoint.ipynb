{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf38be50-b439-4dac-a485-96c4231d0c47",
   "metadata": {},
   "source": [
    "# TRANSFER - LEARNING = IT IS A RESEARCH PROBLEM IN MACHINE LEARNING THAT DEALS WITH STORING KNOWLEDGE GAINED  WHILE SOLVING ONE PROBLEM AND APPLYING IT TO A DIFFERENT BUT RELATED PROBLEM . Eg - KNOWLEDGE  GAINED WHILE LEARNING TO RECOGNIZE CARS SAME CAN BE USED FOR RECOGNIZING TRUCKS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e57214-9193-4572-b52b-2d9a0e1b70d9",
   "metadata": {},
   "source": [
    "# MOBILE_NET_v2 - PRETRAINED MODEL FROM GOOGLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6590350a-d08d-4801-b91b-378577fd1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import PIL.Image as Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_hub as hub\n",
    "import tf_keras\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "classifier = tf_keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098bb9b-229a-455d-a41f-5afe1a4a392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = Image.open('goldfish.jpg').resize(IMAGE_SHAPE)\n",
    "gold_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f06400-882f-4f8d-98dc-e8b9b88b9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_fish = np.array(gold_fish) / 255.0\n",
    "gold_fish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8e1211-6383-4c88-bbb9-bd4fbe559717",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(gold_fish[np.newaxis, ...])\n",
    "result # HERE WE ARE ADDING ONE MORE DIMENSION IN ORDER TO MAKE PREDICTION EASY \n",
    "# THE RESULT SHOWS THE PROBABILITY OF EACH CLASS. HERE CLASS 2 HAS MOST PROBABILITY SO ITS VALUE IS 9.6 AND IT IS \"GOLD FISH\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cfd6c-2482-4a6e-a4f9-95fd0623d08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_index = np.argmax(result)\n",
    "predicted_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f315534-20c1-4341-82d8-a1d0ae3f07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels = []\n",
    "with open(\"ImageNetLabels.txt\" , \"r\") as f:\n",
    "    image_labels = f.read().splitlines()\n",
    "image_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b3ce1-9d9a-42b2-b2b7-5f727ea2a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels[predicted_label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d7087-7931-4a29-8e1b-9e167f69adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)\n",
    "# cache_dir indicates where to download data. I specified . which means current directory\n",
    "# untar true will unzip it\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf8b42-a8e6-4e1c-b0e1-f134f2f53b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "data_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d088f-adae-4e40-8483-f0e8b142ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob('*/*.jpg'))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5933b0-b40d-482f-959e-c53c5b10f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fbe951-c9e9-46b6-9d61-e2ee22ed4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "roses = (list(data_dir.glob('*/*.jpg')))\n",
    "roses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f3160-9074-41d1-9bc6-aac39a47d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(str(roses[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b138aef-f353-4b1d-89f9-da8f289d0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_images_dict = {\n",
    "    'roses': list(data_dir.glob('roses/*')),\n",
    "    'tulips':list(data_dir.glob('tulips/*')),\n",
    "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
    "    'sunflowers':list(data_dir.glob('sunflowers/*')),\n",
    "    'daisy':list(data_dir.glob('daisy/*')),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98066f-d25d-4628-a705-b01508c68d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowers_labels_dict = {\n",
    "    'roses': 0,\n",
    "    'daisy': 1,\n",
    "    'dandelion': 2,\n",
    "    'sunflowers':3,\n",
    "    'tulips':4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f9a00-7040-4d55-99b1-132137f5157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(flowers_images_dict['roses'][0]))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb0cd2-9fd3-43a7-b294-49663b4a7ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.resize(img,IMAGE_SHAPE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29aae59-7b56-4f21-9872-41687d677dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = [] , []\n",
    "for flower_name , images in flowers_images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,IMAGE_SHAPE)\n",
    "        X.append(resized_img)\n",
    "        y.append(flowers_labels_dict[flower_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf45b71-6bcf-471c-8334-9cc9dfbea9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9178f-075b-45e5-9a0a-0c744fdae2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b0cb75-f2c0-46cd-abba-b0f19192d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c75eb-bf5f-47c2-b3c5-272af79c2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(np.array([X[0],X[1],X[2]]))\n",
    "predicted = np.argmax(predicted, axis = 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7767818-71d5-46c4-b8ea-f2c9c27bdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be49ee9c-5ca2-438a-a1e4-f8f6add1af1a",
   "metadata": {},
   "source": [
    "# NOW WE USE PRE- TRAINED MODEL THAT HAS FIXED ITS WEIGHT AND LAYERS EXCEPT THE LAST LAYER FORM ABOVE MODEL . AND WE WONT TRAIN IT AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6c3a9-2e31-4307-ba98-514f9e3caeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94689b-4417-497b-93ae-51eb24a5c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_flowers = 5\n",
    "\n",
    "model = tf_keras.Sequential([\n",
    "  pretrained_model_without_top_layer, # THESE LAYERS ARE PRE- TRAINED \n",
    "  tf_keras.layers.Dense(num_of_flowers) # ONLY THIS LAST LAYER IS USED TO PREDICT CORRECT CLASS\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4c6e8-8557-46f4-90aa-10afe73a639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf_keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865d995-a531-4432-b077-f2b40bbc39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
